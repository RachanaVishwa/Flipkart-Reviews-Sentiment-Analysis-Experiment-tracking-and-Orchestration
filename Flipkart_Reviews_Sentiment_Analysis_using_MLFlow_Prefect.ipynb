{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11aa5648",
   "metadata": {},
   "source": [
    "# Flipkart Reviews Sentiment Analysis using MLFlow and PREFECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f028fe",
   "metadata": {},
   "source": [
    "# Loading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cfe21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fca0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"/Users/rachusarang/Downloads/ILR/reviews_data_dump/reviews_badminton/data.csv\")\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12aaae90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8518, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ee2271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Reviewer_Name', 'Review_Title', 'Place_of_Review', 'Up_Votes',\n",
       "       'Down_Votes', 'Month', 'Review_text', 'Ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [ col.strip().replace(' ', '_') for col in data_df.columns ]\n",
    "\n",
    "data_df.columns = col_names\n",
    "\n",
    "data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9bc1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wonderful                                       416\n",
       "Brilliant                                       303\n",
       "Classy product                                  299\n",
       "Excellent                                       298\n",
       "Perfect product!                                295\n",
       "                                               ... \n",
       "Great shuttle but wised if it’s more durable      1\n",
       "Better game play experience                       1\n",
       "awesome shuttle                                   1\n",
       "Worst experience with Flipkart.                   1\n",
       "For Mavis350                                      1\n",
       "Name: Review_Title, Length: 194, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Review_Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573b7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null values with nan and remove\n",
    "data_df.replace('',np.nan,inplace=True)\n",
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340bed3",
   "metadata": {},
   "source": [
    "# Identify X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae145bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df['Review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10617a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(data_df['Ratings'] >= 4),  # Positive sentiment\n",
    "              (data_df['Ratings'] <= 3),  # Negative sentiment\n",
    "             ]\n",
    "values = [1, 0]  # Labels for positive(1) and negative(0) sentiments\n",
    "\n",
    "y = np.select(conditions, values)\n",
    "\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5685801d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.80644\n",
       "0    0.19356\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a76ad0d",
   "metadata": {},
   "source": [
    "# Split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22270e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250     Product is good as like as bought in the open ...\n",
       "7735                                  Love it...READ MORE\n",
       "2805                                        GoodREAD MORE\n",
       "4914                                       superREAD MORE\n",
       "1539                                   excellentREAD MORE\n",
       "Name: Review_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f03cc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6410,) (6410,)\n",
      "(1603,) (1603,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040b0742",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "435ab92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3604573",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    \n",
    "    #doc = str(doc)\n",
    "    \n",
    "    # Removing special characters and digits\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', ' ', doc)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    doc = re.sub(r'<.*?>', ' ', doc)\n",
    "    \n",
    "    #removing 'READMORE' from reviews\n",
    "    doc = doc.replace(\"READ MORE\", \" \")\n",
    "    \n",
    "    # change sentence to lower case\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in lemmatized_tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Remove punctuation and numbers.\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "    \n",
    "    # Join and return\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f00594cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.8 s, sys: 87.4 ms, total: 1.89 s\n",
      "Wall time: 1.9 s\n",
      "(6410, 2086)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectorizer\n",
    "vect = CountVectorizer(preprocessor=clean)\n",
    "\n",
    "# use it to extract features from training data\n",
    "%time X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "print(X_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d67a2354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1603, 2086)\n"
     ]
    }
   ],
   "source": [
    "# transform testing data (using training data's features)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "print(X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19a069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e55c605",
   "metadata": {},
   "source": [
    "# Running the Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b062a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ad0df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60ad9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4c96283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 20:52:12 INFO mlflow.tracking.fluent: Experiment with name 'Flipkart_Reviews_sentiment_Analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/518147944355896295', creation_time=1711466532436, experiment_id='518147944355896295', last_update_time=1711466532436, lifecycle_stage='active', name='Flipkart_Reviews_sentiment_Analysis', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Flipkart_Reviews_sentiment_Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe00728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('nb', MultinomialNB())\n",
    "    ]\n",
    ")\n",
    "\n",
    "MAX_FEATURES = [1000, 1500, 2000]\n",
    "ALPHA = [1, 10]\n",
    "\n",
    "# Observe the Key Value Pair format\n",
    "parameter_grid = [{'vectorization__preprocessor' : [clean],\n",
    "                   'vectorization__max_features' : MAX_FEATURES, \n",
    "                   'nb__alpha' : ALPHA}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51e853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "CPU times: user 51.6 s, sys: 2.92 s, total: 54.6 s\n",
      "Wall time: 55.2 s\n",
      "Best estimator found on train set\n",
      "Pipeline(steps=[('vectorization',\n",
      "                 CountVectorizer(max_features=2000,\n",
      "                                 preprocessor=<function clean at 0x7f95a3f364c0>)),\n",
      "                ('nb', MultinomialNB(alpha=1))])\n",
      "\n",
      "Score on Test Data:  0.9334819769602378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 20:53:29 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "CPU times: user 59.2 s, sys: 3.64 s, total: 1min 2s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid=parameter_grid, \n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "%time clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best estimator found on train set\")\n",
    "print(clf.best_estimator_)\n",
    "print()\n",
    "\n",
    "print('Score on Test Data: ', clf.score(X_test, y_test))\n",
    "\n",
    "# Initialize the auto logger\n",
    "# max_tuning_runs=None will make sure that all the runs are recorded.\n",
    "# By default top 5 runs will be recorded for each experiment\n",
    "mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    %time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87e870f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import Memory\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "406494e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 946 ms, sys: 71.2 ms, total: 1.02 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "# Improving the efficiency by applying cleaning the text data before hand\n",
    "\n",
    "%time X_train_clean = X_train.apply(lambda doc: clean(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e399238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 238 ms, sys: 17.1 ms, total: 255 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%time X_test_clean = X_test.apply(lambda doc: clean(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "609b1518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 20:56:03 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '63890af00c7e4ea891f14374f736e0e3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/26 20:56:03 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "CPU times: user 2.1 s, sys: 108 ms, total: 2.2 s\n",
      "Wall time: 6.54 s\n",
      "Best estimator found on train set\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer(max_features=2000)),\n",
      "                ('nb', MultinomialNB(alpha=1))])\n",
      "\n",
      "Score on Test Data:  0.9334819769602378\n"
     ]
    }
   ],
   "source": [
    "# Define a memory object to cache intermediate results\n",
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "# Define the pipeline with caching\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('nb', MultinomialNB())\n",
    "    ], \n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "MAX_FEATURES = [1000, 1500, 2000]\n",
    "ALPHA = [1, 10]\n",
    "\n",
    "# Observe the Key Value Pair format\n",
    "parameter_grid = [\n",
    "    {\n",
    "        'vectorization__max_features': MAX_FEATURES,\n",
    "        'nb__alpha': ALPHA\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=parameter_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "%time clf.fit(X_train_clean, y_train)\n",
    "\n",
    "print(\"Best estimator found on train set\")\n",
    "print(clf.best_estimator_)\n",
    "print()\n",
    "\n",
    "print('Score on Test Data: ', clf.score(X_test_clean, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c882a",
   "metadata": {},
   "source": [
    "# Tool - MLFlow\n",
    "\n",
    "\n",
    "MLFlow helps to organize your experiments into runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2b33e",
   "metadata": {},
   "source": [
    "## MLFlow keeps track of - \n",
    "\n",
    "* Tags\n",
    "* Parameters\n",
    "* Metrics\n",
    "* Models\n",
    "* Artifact\n",
    "* Source code, Start and End Time, Authors etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a769fc6",
   "metadata": {},
   "source": [
    "# Auto Logging All Experiment Runs using MLFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19c39c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#from joblib import Memory\n",
    "\n",
    "#import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcb081d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a memory object to cache intermediate results\n",
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ], memory=memory),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    'svc': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ], memory=memory)\n",
    "    \n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__alpha' : [1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000],\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['elasticnet'], \n",
    "            'classifier__l1_ratio': [0.4, 0.5, 0.6],\n",
    "            'classifier__solver': ['saga'],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    ],\n",
    "    'svc': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['linear', 'poly', 'rbf','sigmoid']\n",
    "\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c750b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 20:56:48 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 20:56:56 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 118 ms, total: 3.41 s\n",
      "Wall time: 7.24 s\n",
      "Train Score:  0.9286989633932802\n",
      "Test Score:  0.9356287425149701\n",
      "********** decision_tree **********\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 20:57:15 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 176 ms, total: 14.9 s\n",
      "Wall time: 18.8 s\n",
      "Train Score:  0.9333582776997875\n",
      "Test Score:  0.9291044776119403\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 21:12:08 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 10s, sys: 2.82 s, total: 12min 13s\n",
      "Wall time: 14min 53s\n",
      "Train Score:  0.9332957892990097\n",
      "Test Score:  0.9367481567714396\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "CPU times: user 8min 41s, sys: 1.59 s, total: 8min 42s\n",
      "Wall time: 8min 50s\n",
      "Train Score:  0.9426915961922535\n",
      "Test Score:  0.9466966966966966\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for each algorithm\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='f1', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train, y_train)\n",
    "        \n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test, y_test))\n",
    "        \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4348c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe9fffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer(max_features=5000)),\n",
      "                ('classifier', MultinomialNB(alpha=1))])\n",
      "\n",
      "decision_tree\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer(max_features=1500)),\n",
      "                ('classifier', DecisionTreeClassifier(max_depth=10))])\n",
      "\n",
      "logistic_regression\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer(max_features=5000)),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=1, class_weight='balanced', l1_ratio=0.5,\n",
      "                                    penalty='elasticnet', solver='saga'))])\n",
      "\n",
      "svc\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', TfidfVectorizer(max_features=2000)),\n",
      "                ('classifier', SVC(C=1))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{model}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b141bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6216b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "CPU times: user 6.11 ms, sys: 185 µs, total: 6.29 ms\n",
      "Wall time: 6.3 ms\n",
      "Test Score (F1) 0.9312920089619119\n",
      "Model Size: 179127 Bytes\n",
      "********** decision_tree **********\n",
      "CPU times: user 6.16 ms, sys: 184 µs, total: 6.34 ms\n",
      "Wall time: 6.28 ms\n",
      "Test Score (F1) 0.9190751445086706\n",
      "Model Size: 81385 Bytes\n",
      "********** logistic_regression **********\n",
      "CPU times: user 5.72 ms, sys: 128 µs, total: 5.84 ms\n",
      "Wall time: 5.85 ms\n",
      "Test Score (F1) 0.919226393629124\n",
      "Model Size: 109498 Bytes\n",
      "********** svc **********\n",
      "CPU times: user 145 ms, sys: 674 µs, total: 146 ms\n",
      "Wall time: 146 ms\n",
      "Test Score (F1) 0.9275045537340619\n",
      "Model Size: 465562 Bytes\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(\"*\"*10, name, \"*\"*10)\n",
    "    \n",
    "    joblib.dump(model, f'/Users/rachusarang/Downloads/ILR/reviews_data_dump/Sentimentanalysis_badminton/{name}.pkl')\n",
    "    model = joblib.load(f'/Users/rachusarang/Downloads/ILR/reviews_data_dump/Sentimentanalysis_badminton/{name}.pkl')\n",
    "    \n",
    "    %time y_test_pred = model.predict(X_test_clean)\n",
    "    print(\"Test Score (F1)\", metrics.f1_score(y_test, y_test_pred))\n",
    "    \n",
    "    print(\"Model Size:\", os.path.getsize(f'/Users/rachusarang/Downloads/ILR/reviews_data_dump/Sentimentanalysis_badminton/{name}.pkl'), \"Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76caa3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6f24ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the auto logger\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c55834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a971fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d06f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3454a",
   "metadata": {},
   "source": [
    "# Custom Experiment Tracking and Database Integration with MLFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbde476",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow_1.db\")\n",
    "\n",
    "mlflow.set_experiment(\"Flipkart reviews sentiment analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2987d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Train Score:  0.8812792511700469\n",
      "Test Score:  0.8920773549594511\n",
      "Fit Time:  2.6011757850646973\n",
      "Predict Time:  0.008444070816040039\n",
      "Model Size:  87911\n",
      "\n",
      "********** decision_tree **********\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Train Score:  0.8875195007800312\n",
      "Test Score:  0.8814722395508422\n",
      "Fit Time:  13.859179973602295\n",
      "Predict Time:  0.010019063949584961\n",
      "Model Size:  68873\n",
      "\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Train Score:  0.8931357254290171\n",
      "Test Score:  0.8983156581409857\n",
      "Fit Time:  739.7374629974365\n",
      "Predict Time:  0.008857965469360352\n",
      "Model Size:  109498\n",
      "\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Train Score:  0.9042121684867395\n",
      "Test Score:  0.9082969432314411\n",
      "Fit Time:  523.3775610923767\n",
      "Predict Time:  0.11654090881347656\n",
      "Model Size:  346010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev = \"Rachana\"\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "\n",
    "    # Fit\n",
    "    start_fit_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_fit_time = time.time()\n",
    "\n",
    "    # Predict\n",
    "    start_predict_time = time.time()\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    end_predict_time = time.time()\n",
    "\n",
    "    # Saving the best model\n",
    "    joblib.dump(grid_search.best_estimator_, f'/Users/rachusarang/Downloads/ILR/reviews_data_dump/Sentimentanalysis_badminton/{algo}.pkl')\n",
    "    model_size = os.path.getsize(f'/Users/rachusarang/Downloads/ILR/reviews_data_dump/Sentimentanalysis_badminton/{algo}.pkl')\n",
    "\n",
    "    # Pring Log\n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test, y_test))\n",
    "    print(\"Fit Time: \", end_fit_time - start_fit_time)\n",
    "    print(\"Predict Time: \", end_predict_time - start_predict_time)\n",
    "    print(\"Model Size: \", model_size)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    # Start the experiment run\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log tags with mlflow.set_tag()\n",
    "        mlflow.set_tag(\"developer\", dev)\n",
    "\n",
    "        # Log Parameters with mlflow.log_param()\n",
    "        mlflow.log_param(\"algorithm\", algo)\n",
    "        mlflow.log_param(\"hyperparameter_grid\", param_grids[algo])\n",
    "        mlflow.log_param(\"best_hyperparameter\", grid_search.best_params_)\n",
    "\n",
    "        # Log Metrics with mlflow.log_metric()\n",
    "        mlflow.log_metric(\"train_score\", grid_search.best_score_)\n",
    "        mlflow.log_metric(\"test_score\", grid_search.score(X_test, y_test))\n",
    "        mlflow.log_metric(\"fit_time\", end_fit_time - start_fit_time)\n",
    "        mlflow.log_metric(\"predict_time\", end_predict_time - start_predict_time)\n",
    "        mlflow.log_metric(\"model_size\", model_size)\n",
    "\n",
    "        # Log Model using mlflow.sklearn.log_model()\n",
    "        mlflow.sklearn.log_model(grid_search.best_estimator_, f\"{algo}_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7f21d",
   "metadata": {},
   "source": [
    "###### Model Registry provides functionality for managing and versioning machine learning models and their associated metadata. It allows data scientists and machine learning engineers to track, share, and collaborate on models throughout their lifecycle, from experimentation to production deployment.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "* Model Registration\n",
    "* Model Versioning\n",
    "* Stage Transitions\n",
    "* Intra Team Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52863904",
   "metadata": {},
   "source": [
    "### Archived: These versions are no longer in active use.\n",
    "### Staged: These versions are ready for deployment pending final validation.\n",
    "### Production: These versions are actively serving users in live environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521f5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9637c7a0",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966b120",
   "metadata": {},
   "source": [
    "Orchestration refers to the coordination and management of various tasks, resources, and processes involved in the end-to-end machine learning lifecycle. This includes:\n",
    "\n",
    "1. Data Preparation and Management\n",
    "2. Model Training\n",
    "3. Experimentation and Evaluaiton\n",
    "4. Model Deployment\n",
    "5. Monitor and Management\n",
    "6. Automation of repetitive tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c76a50",
   "metadata": {},
   "source": [
    "## Introducing Prefect\n",
    "Prefect is an open-source orchestration and observability platform that empowers developers to build and scale resilient code quickly, turning their Python scripts into resilient, recurring workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabd1e1",
   "metadata": {},
   "source": [
    "## Why Prefect?\n",
    "\n",
    "* Python based open source tool\n",
    "* Manage ML Pipelines\n",
    "* Schedule and Monitor the flow\n",
    "* Gives observability into failures\n",
    "* Native dask integration for scaling (Dask is used for parallel computing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb500368",
   "metadata": {},
   "source": [
    "# Refactoring the ML Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28057dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4f45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#import string\n",
    "#import re\n",
    "#import nltk\n",
    "##from nltk.tokenize import word_tokenize\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import joblib\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from joblib import Memory\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4f936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4747cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = [ col.strip().replace(' ', '_') for col in df.columns ]\n",
    "    \n",
    "    df['Ratings'] = pd.Series(np.select([(df['Ratings'] >= 4), (df['Ratings'] <= 3)], [1, 0]))\n",
    "    \n",
    "    # replace null values with nan and remove\n",
    "    df.replace('',np.nan,inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "@task\n",
    "def input_output(data, input, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    X = data[input]\n",
    "    y = data[output]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "@task\n",
    "def split_train_test(X, y, test_size=0.25, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "\n",
    "@task\n",
    "def train_model(X_train, y_train, **hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    cachedir = '.cache'\n",
    "    memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory)\n",
    "\n",
    "    clf = GridSearchCV(estimator=pipe,\n",
    "                       param_grid=hyperparameters,\n",
    "                       scoring='f1',\n",
    "                       cv=4,\n",
    "                       return_train_score=True,\n",
    "                       verbose=1\n",
    "                      )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "@task\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_score = metrics.f1_score(y_train, y_train_pred)\n",
    "    test_score = metrics.f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af056abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78035647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data_df['Review_text']\n",
    "\n",
    "#y = pd.Series(np.select([(data_df['Ratings'] >= 4), (data_df['Ratings'] <= 3)], [1, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047d7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow\n",
    "\n",
    "@flow(name=\"Multinomial Naive Bayes Training\")\n",
    "def workflow():\n",
    "    data_path = \"/Users/rachusarang/Downloads/ILR/reviews_data_dump/reviews_badminton/data.csv\"\n",
    "    INPUT = 'Review_text'\n",
    "    OUTPUT = 'Ratings'\n",
    "    HYPERPARAMETERS = {\n",
    "        'vectorization': [CountVectorizer()],\n",
    "        'vectorization__max_features' : [5000], \n",
    "        'classifier__alpha' : [1]\n",
    "    }\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(data_path)\n",
    "\n",
    "    # Identify Inputs and Output\n",
    "    X, y = input_output(df, INPUT, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(X_train, y_train, **HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cead3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.432 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Multinomial Naive Bayes Training'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.432 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'bizarre-skink'\u001b[0m for flow\u001b[1;35m 'Multinomial Naive Bayes Training'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.436 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/d4adf780-6eac-4411-aeaa-69629ebd4609</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.436 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/d4adf780-6eac-4411-aeaa-69629ebd4609\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.501 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Created task run 'load_data-0' for task 'load_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.501 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Created task run 'load_data-0' for task 'load_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.503 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Executing 'load_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.503 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Executing 'load_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.600 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.600 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.622 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Created task run 'input_output-0' for task 'input_output'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.622 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Created task run 'input_output-0' for task 'input_output'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.624 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Executing 'input_output-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.624 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Executing 'input_output-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.684 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'input_output-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.684 | \u001b[36mINFO\u001b[0m    | Task run 'input_output-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.709 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Created task run 'split_train_test-0' for task 'split_train_test'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.709 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Created task run 'split_train_test-0' for task 'split_train_test'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.710 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Executing 'split_train_test-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.710 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Executing 'split_train_test-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.770 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_train_test-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.770 | \u001b[36mINFO\u001b[0m    | Task run 'split_train_test-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.794 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Created task run 'train_model-0' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.794 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Created task run 'train_model-0' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:29.795 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Executing 'train_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:29.795 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Executing 'train_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:30.143 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:30.143 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:30.169 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Created task run 'evaluate_model-0' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:30.169 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Created task run 'evaluate_model-0' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:30.171 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Executing 'evaluate_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:30.171 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Executing 'evaluate_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:30.285 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:30.285 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9410821643286573\n",
      "Test Score: 0.9363989250522544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">06:26:30.348 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bizarre-skink'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "06:26:30.348 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bizarre-skink'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37721b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce25ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43bd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89888c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaab538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e30b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631b751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6f0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827826d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01000122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3544bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3b300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686811db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23880161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7d36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0757319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d68b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c6704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10860551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66361a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b6d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
